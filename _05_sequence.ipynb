{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as mpanim\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from baseline_3d_pose.utils import *\n",
    "from baseline_3d_pose.model import *\n",
    "from baseline_3d_pose.viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options():\n",
    "    def __init__(self):\n",
    "        # paths\n",
    "        self.data_path = Path('data')\n",
    "        self.model_path = Path('model')\n",
    "        \n",
    "        # train options\n",
    "        self.actions = 'All'\n",
    "        self.attempt_id = '01'\n",
    "        self.attempt_path = Path('model')/self.attempt_id\n",
    "        \n",
    "        self.load_ckpt = False\n",
    "        \n",
    "        # train hyper-params\n",
    "        self.bs = 128\n",
    "        self.epochs = 10\n",
    "        self.lr = 1e-3\n",
    "        \n",
    "        # model hyper-params\n",
    "        self.size = 1024\n",
    "        self.stages = 2\n",
    "        self.dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.ls = lambda x: list(x.iterdir()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_3d = torch.load(data_path/'stat_3d.pt')\n",
    "stat_2d = torch.load(data_path/'stat_2d.pt')\n",
    "train_set_2d = torch.load(data_path/'train_2d.pt')\n",
    "rcams = torch.load(data_path/'rcams.pt')\n",
    "mean_2d = stat_2d['mean']\n",
    "std_2d = stat_2d['std']\n",
    "dim_use_2d = stat_2d['dim_use']\n",
    "dim_ignore_2d = stat_2d['dim_ignore']\n",
    "mean_3d = stat_3d['mean']\n",
    "std_3d = stat_3d['std']\n",
    "dim_use_3d = stat_3d['dim_use']\n",
    "dim_ignore_3d = stat_3d['dim_ignore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = Path(\"imgs\")\n",
    "json_path = Path(\"json\")\n",
    "data_path = Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_seq = imgs_path/'crop_img_seq/'\n",
    "out_seq = imgs_path/'crop_out_seq/'\n",
    "kp_seq = json_path/'crop_json/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (ln_in): Linear(in_features=32, out_features=1024, bias=True)\n",
       "  (bn_in): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lins): ModuleList(\n",
       "    (0): ResLinear(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (drop): Dropout(p=0.5, inplace=False)\n",
       "      (ln1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ln3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResLinear(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (drop): Dropout(p=0.5, inplace=False)\n",
       "      (ln1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ln3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_out): Linear(in_features=1024, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = torch.load('model/01/options.pt')\n",
    "\n",
    "model = Model()\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=options.lr)\n",
    "\n",
    "model_state = torch.load(options.attempt_path/'last_model.pt')\n",
    "optimizer_state = torch.load(options.attempt_path/'last_optimizer.pt')\n",
    "model.load_state_dict(model_state)\n",
    "optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lists = sorted(img_seq.ls())\n",
    "out_lists = sorted(out_seq.ls())\n",
    "kp_lists = sorted(kp_seq.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = 290\n",
    "# for idx, (img, kp) in enumerate(zip(img_lists, kp_lists)):\n",
    "#     kl = get_kp_from_json(kp)\n",
    "#     kps = coco_to_skel(kl)\n",
    "#     hip = (int(kps[0][0]), int(kps[0][1]))\n",
    "    \n",
    "#     inp = cv2.imread(str(img))\n",
    "#     inp = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "#     crop = inp[hip[1]-size//2:hip[1]+size//2 , hip[0]-size//2:hip[0]+size//2]\n",
    "#     crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "#     cv2.imwrite(str(imgs_path/f'crop_img_seq/{idx:05d}.jpg'), crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 39\n",
    "# idx = 167\n",
    "img = mpimg.imread(img_lists[idx])\n",
    "out = mpimg.imread(out_lists[idx])\n",
    "kp = coco_to_skel(get_kp_from_json(kp_lists[idx]) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_norm = normalize_kp(kp, mean_2d, std_2d, dim_use_2d)\n",
    "kp_unnorm = unnormalize_data(kp_norm, mean_2d, std_2d, dim_ignore_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'Directions', 'Directions.54138969.h5')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = list(train_set_2d.keys())[4]\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_t = torch.from_numpy(kp_norm).float()\n",
    "kp_t3d = model(kp_t.cuda())\n",
    "kp_3d = kp_t3d.cpu().detach().numpy()\n",
    "kp_3d = unnormalize_data(kp_3d, mean_3d, std_3d, dim_ignore_3d)\n",
    "kp_3d = cam_to_world_centered(kp_3d, key, rcams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "gs = GridSpec(2, 2)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1])\n",
    "ax2 = plt.subplot(gs[2])\n",
    "ax3 = plt.subplot(gs[3], projection='3d')\n",
    "ax3.view_init(elev=20, azim=70)\n",
    "\n",
    "ax0.set_title('Input Image')\n",
    "ax1.set_title('COCO Pose')\n",
    "ax2.set_title('Custom Pose')\n",
    "ax3.set_title('3D Pose Predictions')\n",
    "\n",
    "ax0.imshow(img)\n",
    "ax1.imshow(out)\n",
    "\n",
    "show_2d_pose(kp_unnorm, ax2)\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "show_3d_pose(kp_3d, ax3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ls = []\n",
    "# out_ls = []\n",
    "# kp_ls = []\n",
    "# kp3d_ls = []\n",
    "\n",
    "# for i in range(len(img_lists)):\n",
    "#     img_ls.append(mpimg.imread(img_lists[i]))\n",
    "#     out_ls.append(mpimg.imread(out_lists[i]))\n",
    "    \n",
    "#     kp = coco_to_skel(get_kp_from_json(kp_lists[i]) * 2)\n",
    "#     kp_norm = normalize_kp(kp, mean_2d, std_2d, dim_use_2d)\n",
    "#     kp_unnorm = unnormalize_data(kp_norm, mean_2d, std_2d, dim_ignore_2d)\n",
    "#     kp_ls.append(kp_unnorm)\n",
    "    \n",
    "#     kp_t = torch.from_numpy(kp_norm).float()\n",
    "#     kp_t3d = model(kp_t.cuda())\n",
    "#     kp_3d = kp_t3d.cpu().detach().numpy()\n",
    "#     kp_3d = unnormalize_data(kp_3d, mean_3d, std_3d, dim_ignore_3d)\n",
    "#     kp_3d = cam_to_world_centered(kp_3d, key, rcams)\n",
    "#     kp3d_ls.append(kp_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## %matplotlib qt\n",
    "\n",
    "# fig = plt.figure(figsize=(15,15))\n",
    "# gs = GridSpec(2, 2)\n",
    "# ax0 = plt.subplot(gs[0])\n",
    "# ax1 = plt.subplot(gs[1])\n",
    "# ax2 = plt.subplot(gs[2])\n",
    "# ax3 = plt.subplot(gs[3], projection='3d')\n",
    "# ax3.view_init(elev=20, azim=70)\n",
    "\n",
    "# img0 = None\n",
    "# img1 = None\n",
    "# for i in range(len(img_lists)):\n",
    "# # for i in range(3):\n",
    "#     if img0 is None:\n",
    "#         img0 = ax0.imshow(img_ls[i])\n",
    "#     else:\n",
    "#         img0.set_data(img_ls[i])\n",
    "        \n",
    "#     if img1 is None:\n",
    "#         img1 = ax1.imshow(out_ls[i])\n",
    "#     else:\n",
    "#         img1.set_data(out_ls[i])\n",
    "        \n",
    "#     ax2.clear()\n",
    "#     show_2d_pose(kp_ls[i], ax2)\n",
    "#     ax2.invert_yaxis()\n",
    "    \n",
    "#     ax3.clear()\n",
    "#     show_3d_pose(kp3d_ls[i], ax3)\n",
    "        \n",
    "#     plt.pause(1e-25)\n",
    "#     plt.draw()\n",
    "#     plt.savefig(f'imgs/asd/bro{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_path/'asd'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
