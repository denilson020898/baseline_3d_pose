# AUTOGENERATED! DO NOT EDIT! File to edit: 04_train.ipynb (unless otherwise specified).

__all__ = ['Options', 'save_options', 'save_ckpt', 'options', 'stat_3d', 'stat_2d', 'rcams', 'mean_2d', 'std_2d',
           'dim_use_2d', 'dim_ignore_2d', 'mean_3d', 'std_3d', 'dim_use_3d', 'dim_ignore_3d', 'train', 'test', 'model',
           'model', 'criterion', 'optimizer', 'train_ds', 'train_dl', 'test_ds', 'test_dl', 'options', 'model_state',
           'optimizer_state', 'json_path', 'kp', 'kps', 'kps_norm', 'kps_unnorm', 'kps_tnsr', 'kps_tnsr_3d', 'kps_3d',
           'key', 'kps_3d', 'kps_3d', 'gs', 'ax', 'ax2']

# Cell
from .utils import *
from .model import *
from .dataset import *
from .viz import *
from fastai.vision import *
from fastprogress.fastprogress import master_bar, progress_bar
import json
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from matplotlib.gridspec import GridSpec

# Cell
class Options():
    def __init__(self):
        # paths
        self.data_path = Path('data')
        self.model_path = Path('model')

        # train options
        self.actions = 'All'
        self.attempt_id = '01'
        self.attempt_path = Path('model')/self.attempt_id

        self.load_ckpt = False

        # train hyper-params
        self.bs = 128
        self.epochs = 10
        self.lr = 1e-3

        # model hyper-params
        self.size = 1024
        self.stages = 2
        self.dropout = 0.5

# Cell
def save_options(options):
    options.attempt_path.mkdir(exist_ok=True)
    torch.save(options, options.attempt_path/'options.pt')

# Cell
def save_ckpt(model_state, optimizer_state, options, is_best=False):
    options.attempt_path.mkdir(exist_ok=True)
    model_name = 'best_model.pt' if is_best else 'last_model.pt'
    optimizer_name = 'best_optimizer.pt' if is_best else 'last_optimizer.pt'
    torch.save(model_state, options.attempt_path/model_name)
    torch.save(optimizer_state, options.attempt_path/optimizer_name)

# Cell
options = Options()

# Cell
stat_3d = torch.load(data_path/'stat_3d.pt')
stat_2d = torch.load(data_path/'stat_2d.pt')
rcams = torch.load(data_path/'rcams.pt')

mean_2d = stat_2d['mean']
std_2d = stat_2d['std']
dim_use_2d = stat_2d['dim_use']
dim_ignore_2d = stat_2d['dim_ignore']

mean_3d = stat_3d['mean']
std_3d = stat_3d['std']
dim_use_3d = stat_3d['dim_use']
dim_ignore_3d = stat_3d['dim_ignore']

# Cell
def train(train_dl, model, criterion, optimizer, options, mb):
    model.train()
    loss_list = []
    skel_loss_list = []
    for xb, yb in progress_bar(train_dl, parent=mb):
        xb, yb = xb.cuda(), yb.cuda()
        yhat = model(xb)
        optimizer.zero_grad()
        loss_skel = criterion(yhat, yb)
        loss = loss_skel.mean()
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)
        optimizer.step()

        loss_list.append(loss.item())
        skel_loss_list.append(loss_skel.data.cpu().numpy())

        mb.child.comment = f'train loss: {loss.item()}'
    return loss_list, skel_loss_list

# Cell
def test(test_dl, model, criterion, options, mb):
    model.eval()
    loss_list = []
    skel_loss_list = []
    for xb, yb in progress_bar(test_dl, parent=mb):
        xb, yb = xb.cuda(), yb.cuda()
        with torch.no_grad():
            yhat = model(xb)
            loss_skel = criterion(yhat, yb)
            loss = loss_skel.mean()
        loss_list.append(loss.item())
        skel_loss_list.append(loss_skel.data.cpu().numpy())
        mb.child.comment = f'test loss: {loss.item()}'
    return loss_list, skel_loss_list

# Cell
model = Model()
model = model.cuda()
model.apply(init_kaiming)
print(f'total params: {sum(p.numel() for p in model.parameters())}')

criterion = nn.MSELoss(reduction='none').cuda()
optimizer = optim.Adam(model.parameters(), lr=options.lr)

if options.load_ckpt:
    options = torch.load('model/01/options.pt')
    model_state = torch.load(options.attempt_path/'last_model.pt')
    optimizer_state = torch.load(options.attempt_path/'last_optimizer.pt')
    model.load_state_dict(model_state)
    optimizer.load_state_dict(optimizer_state)

# Cell
train_ds = Human36Dataset(get_actions(options.actions), options.data_path, is_train=True)
train_dl = DataLoader(train_ds, batch_size=options.bs, shuffle=True)
test_ds = Human36Dataset(get_actions(options.actions), options.data_path, is_train=False)
test_dl = DataLoader(test_ds, batch_size=options.bs, shuffle=False)

# Cell
options = torch.load('model/01/options.pt')
model_state = torch.load(options.attempt_path/'last_model.pt')
optimizer_state = torch.load(options.attempt_path/'last_optimizer.pt')

model.load_state_dict(model_state)
optimizer.load_state_dict(optimizer_state)

# Cell
model.eval()

# Cell
json_path = Path('json')

# Cell
kp = get_kp_from_json(json_path/'kp2.json')
kps = coco_to_skel(kp)

# Cell
kps_norm = normalize_kp(kps, mean_2d, std_2d, dim_use_2d)
kps_unnorm = unnormalize_data(kps_norm, mean_2d, std_2d, dim_ignore_2d)

# Cell
kps_tnsr = torch.from_numpy(kps_norm).float()
kps_tnsr_3d = model(kps_tnsr.cuda())

kps_3d = kps_tnsr_3d.cpu().detach().numpy()
key = train_ds.get_key(0)
kps_3d = unnormalize_data(kps_3d, mean_3d, std_3d, dim_ignore_3d)
kps_3d = cam_to_world_centered(kps_3d, key, rcams)

# Cell
plt.figure(figsize=(12,6))
gs = GridSpec(1,2)
gs.update(wspace=0.05, hspace=0.05)
ax = plt.subplot(gs[0])
ax2 = plt.subplot(gs[1], projection='3d')

show_2d_pose(kps_unnorm, ax)
ax.invert_yaxis()

show_3d_pose(kps_3d, ax2)

plt.show()